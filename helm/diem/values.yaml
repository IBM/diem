ingress:
  ## name is the name of your ingress file
  name: diem-ingress

  ## the name of the version v1 or v1beta
  version: v1

  ## tls will be the name of your tls secret. It will be created for you if don't have one
  ## Otherwise get the tls from your cluster
  ## kubectl describe ingress diem-ingress
  ##  TLS: diem-tls-secret terminates example.com
  createtls: true
  tls: diem-tls-secret

  ## host is the hostname of your application
  host: bizops.ibm.com

common:
  config:
    diemAdminRbac: diem-rbac
    diemAdmin: diem-admin
    configmapref: diem-common-config
    K8_SYSTEM_NAME: "Diem on CRC UAT"
    K8_SYSTEM: uat
    K8_INSTANCE: US

  secrets:
    ## secretmapref is the name of the common secret map ref
    secretmapref: diem-common-secret
    SLACKHOOK: ""

## these are the settings for Diem Core
core:
  ## this relates to the diem-core deployment
  deployment:
    ## name is the name of the deployment
    name: diem-core

    ## socketName is the url the client ui socket will connect to
    ## for the moment Do Not Change this
    socketName: etl-socket-server

    tier: backend
    version: 1.0.0
    image: quay.io/diem/core
    replicas: 1
    port: 8080

    ## targetPort is the port diem-core pod will run under
    targetPort: 8192

  config:
    ## configmapref is the name of the common config map ref
    configmapref: diem-core-config

    ## important, the path the application will run under
    APPPATH: /etl-mgr

    spark:
      SPARK_IMAGE: quay.io/diem/pyspark:3.1.1-rc1
      SPARK_IMAGEPULLSECRETS: regsecret
      OPERATOR_DRIVER_CORES: "2"
      OPERATOR_DRIVER_MEMORY: 1024m
      OPERATOR_EXECUTOR_CORES: 8
      OPERATOR_EXECUTOR_INSTANCES: 2
      OPERATOR_EXECUTOR_MEMORY: 8G

    volume:
      volumeName: spark-data
      volumeMountPath: /shared
      volumeClaimName: spark-shared-data

    ## Slack integration, enable it by putting the enabled to true
    slack:
      enabled: false
      SLACK_EMOJI: ":diem:"
      SLACK_DEPLOY_CHANNEL: "#diem-deploy-uat"
      SLACK_DEPLOY_USERNAME: "diem- (Notification)"
      SLACK_INTERNAL_CHANNEL: "#diem-bugs-uat"
      SLACK_INTERNAL_USERNAME: "diem - (Internal)"
      SLACK_USER_CHANNEL: "#diem-bugs-uat"
      SLACK_USER_USERNAME: "diem - (User)"

    ## Integrate your own cloud object storage
    ## leave this blank if you want to use minio integrated as a dependency
    ## if these value are going to be used, disable minio
    s3:
      enabled: false
      apiKeyId: ""
      endpoint: ""
      serviceInstanceId: ""
      signatureVersion: ""

  ##
  secrets:
    secretmapref: diem-core-secret
    SESSION_NAME: etl.sid
    SESSION_SECRET: ETLSECRETPW
    MONGO_URL: ""
    SENDGRID_API: ""
    JWTTOKEN: ""

  ## OpenId authentication
  auth:
    clientId: ""
    clientSecret: ""
    discoveryUrl: ""
    callbackUrl: sso/callback

nodepy:
  ## configmapref is the name of the nodepy config map ref
  configmapref: diem-nodepy-config
  secretmapref: diem-nodepy-config

  ## image is the the name of the nodepy image
  image: quay.io/diem/nodepy
  name: diem-nodepy
  port: 8080
  replicas: 1
  targetPort: 8192
  tier: backend
  version: 1.0.0

## cnfiguration for the operator
operator:
  ## configmapref is the name of the nodepy config map ref
  configmapref: diem-operator-config
  secretmapref: diem-operator-config

  ## image is the the name of the nodepy image
  image: quay.io/diem/operator
  name: diem-operator
  port: 8080
  replicas: 1
  targetPort: 8192
  tier: backend
  version: 1.0.0

## enable the spark Operator
## for more details see
## https://github.com/GoogleCloudPlatform/spark-on-k8s-operator
spark-operator:
  ## overwrite the spark job namespace if needed, otherwise it will
  ## run in the default namespace
  sparkJobNamespace: ""

  ## enables the spark webhoob
  enableWebhook: true
  serviceAccounts:
    spark:
      name: spark
  image:
    repository: quay.io/diem/spark-operator
    tag: 2.0.0

mongodb:
  createservice: true
  auth:
    username: diemadmin
    rootPassword: diemadmin
    password: diempassword
    database: ibmclouddb

## Nats
## see https://github.com/bitnami/charts/tree/master/bitnami/nats

nats:
  createservice: true
  ## the name of the service
  name: nats

  ## authentication
  ## it4s recommended you create your own long encrypted password
  ## follow the instructions here https://docs.nats.io/nats-tools/natscli
  ## either fill in the password in plain text or
  ## encrypt your password and fill in your plain password in the unencrypted_password
  ## if you do not want to use an encrypted password leave the unencrypted_password blank
  ## example
  ##    unencrypted_password: natsuserauthorisationpassword
  ##    password: $2a$11$4X.WN5r4PeaB4vYMtbFsEOKJTSxEiWuCq/FV25RsWZvLFSEeDOrf6
  ##
  auth:
    user: nats_client
    unencrypted_password: ""
    password: ""
    token: ""
  clusterAuth:
    user: ""
    password: ""
    token: ""

  ## enable external access, this will create a load balancer
  ## you can get your ip from >_ kubectl get svc diem-nats-lb -o wide
  external: false

  ## only if external is enabled (will be your loadbalancer ip)
  ## you might need to reapply the helm chart twice once you have it
  ip: 0.0.0.0

  priorityClassName: system-node-critical

  replicaCount: 1

  extraFlags:
    cluster_name: diem-nats-cluster
    no_advertise: true

minio:
  createservice: true
  accessKey: diemadmin
  secretKey: diempassword

  persistence:
    ## use an existing claim
    # existingClaim: spark-shared-data
    # VolumeName: spark-data

    ## depending on your capacity you can increase this amount
    size: 20Gi

  mountPath: /minio
  securityContext:
    enabled: false
  resources:
    requests:
      memory: 1Gi
